{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinGyeongdo/Sesion2_projcet/blob/main/Moviedata_crawling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y0J_UW_Mi_ie",
      "metadata": {
        "id": "Y0J_UW_Mi_ie"
      },
      "source": [
        "- 해당 코드는 다음 블로그 : https://developer-ankiwoong.tistory.com/843?category=847288 를 참고하여 작성하였습니다.\n",
        "\n",
        "- 참고자료\n",
        "https://warm-uk.tistory.com/43"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "04c18f74",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Skipping fakeagent as it is not installed.\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall fakeagent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "f300ce1f",
      "metadata": {
        "id": "f300ce1f"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from requests import get\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import sleep\n",
        "from random import randint\n",
        "import pymysql\n",
        "from user_agent import generate_user_agent, generate_navigator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H868PD4ejMfF",
      "metadata": {
        "id": "H868PD4ejMfF"
      },
      "source": [
        "- 구글의 개발자 도구를 사용하여 해당 블럭에 매칭 되는 HTML 코드를 탐색하고, Feature들을 활용한 총 매출 예측을 만들기 위하여 최신 데이터를 수집하는 과정입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "7d6b752c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import time\n",
        "def review_crawl(page_num):\n",
        "    \"\"\"\n",
        "    페이지당 10개의 리뷰를 가져오는 함수 입니다.\n",
        "    예) 50000개의 리뷰를 가져오고 싶다면, page_num = 5000 입력\n",
        "    \"\"\"\n",
        "    # chrome_ver = chromedriver_autoinstaller.get_chrome_version().split('.')[0]  #크롬드라이버 버전 확인\n",
        "    # options = webdriver.ChromeOptions()\n",
        "    # options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
        "    # #options.add_argument('--start-fullscreen')\n",
        "    # #options.add_argument(\"headless\")\n",
        "    # try:\n",
        "    #     driver = webdriver.Chrome(f'./{chrome_ver}/chromedriver.exe', options = options)   \n",
        "    # except:\n",
        "    #     chromedriver_autoinstaller.install(True)\n",
        "    #     driver = webdriver.Chrome(f'./{chrome_ver}/chromedriver.exe', options = options)\n",
        "        \n",
        "    titles = []\n",
        "    rates = []\n",
        "    reviews = []\n",
        "    pages = np.arange(1, page_num+1, 1)\n",
        "    for page in pages:\n",
        "        navigator = generate_navigator()\n",
        "        headers = {'user_agent' : navigator['user_agent'] }\n",
        "        base_url = \"https://movie.naver.com/movie/point/af/list.naver\"\n",
        "        homepage = requests.get(base_url+f\"?&page={page}\", headers=headers)\n",
        "        soup = BeautifulSoup(homepage.text, \"html.parser\") # html 파싱\n",
        "        movie_body = soup.find_all('tbody')   \n",
        "\n",
        "        for i in range(1,11):\n",
        "            \n",
        "            try:                      \n",
        "                \n",
        "                # CSS selector를 활용하여 데이터를 수집합니다.\n",
        "                \n",
        "                             \n",
        "                # 제목\n",
        "                title = soup.select(f\"tbody > tr:nth-child({i}) > td.title > a.movie.color_b\")[0].text\n",
        "                titles.append(title)\n",
        "                # 평점\n",
        "                rate = soup.select(f\"tbody > tr:nth-child({i}) > td.title > div > em\")[0].text\n",
        "                rates.append(rate)\n",
        "                # 리뷰\n",
        "                review = soup.select(f\"tbody > tr:nth-child({i}) > td.title\")[0].text\n",
        "                p = re.compile('{}(.*){}'.format(re.escape('\\n\\n'), re.escape('\\n\\t')))\n",
        "                review = p.findall(review)\n",
        "                try:\n",
        "                    reviews.append(review[0][0:200])\n",
        "                except:\n",
        "                    reviews.append(np.nan)       \n",
        "            except:\n",
        "                break          \n",
        "        # 자주 접근하여 홈페이지 접속을 방해하는 행위 방지.\n",
        "        time.sleep(2) \n",
        "     \n",
        "    # 알맞은 데이터개수가 들어갔는지 확인합니다.\n",
        "    print(\"Titles: \", len(titles))\n",
        "    print(\"rates : \", len(rates))\n",
        "    print(\"reviews : \", len(reviews))\n",
        "\n",
        "\n",
        "\n",
        "    return titles, rates, reviews\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "6f3a6cc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_df(titles, rates, reviews):\n",
        "    df = pd.DataFrame({\n",
        "        'titles' : titles,\n",
        "        'rates' : rates,\n",
        "        'reviews' : reviews,\n",
        "        })\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "f003c09a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine\n",
        "from datetime import datetime\n",
        "\n",
        "def insert_db(df):\n",
        "\n",
        "    pymysql.install_as_MySQLdb()\n",
        "    import MySQLdb\n",
        "\n",
        "    engine = create_engine(\"mysql+mysqldb://root:0000@localhost:3306/comento\", encoding='utf-8')\n",
        "    conn = engine.connect()\n",
        "    df.to_sql(name=f'movie_review({datetime.today()})', con=engine, if_exists='append', index=False)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "9e4f3bcb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Titles:  10000\n",
            "rates :  10000\n",
            "reviews :  10000\n"
          ]
        }
      ],
      "source": [
        "titles, rates, reviews = review_crawl(1000)\n",
        "\n",
        "movie = convert_df(titles, rates, reviews)\n",
        "insert_db(movie)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Untitled-checkpoint.ipynb의 사본",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('project4')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "a835adf61a786e380bfa92053441762c09425bfcd81fe25cb2610a3115f6f377"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
